---
title: "Plugins in Rust: Diving into dynamic loading"
description: "A closer look at dynamic loading in Rust"
summary: "Writing a more advanced example of dynamic loading working, and
analyzing the results."
author: "Mario Ortiz Manero"
tags: ["rust", "journal"]
series: ["rust-plugins"]
date: 2021-09-09
GHissueID: ??
---

:sectnums:
:stem: latexmath

:repr-c: pass:quotes[`#[repr\(C)]`]

== Introduction

In the https://nullderef.com/blog/plugin-start/[last part] of this
https://nullderef.com/series/rust-plugins/[series] I wrote some simple
experiments of plugins both with WebAssembly and dynamic loading. After
discarding Wasm for this specific PDK, I wanted to try to get a more realistic
example with dynamic loading and work towards the final implementation.

Since the Tremor team suggested to begin by implementing connectors, we'll first
have to learn more about them. Matthias ran me through their current state in a
meeting, which I'll try to summarize:

== Learning more about connectors

////
2021-09-07 MEETING NOTES (CONNECTORS):

Connector trait:
* can contain a source, a sink, or both
* handlers like `on_start`, `on_pause`, etc
* `connect` retries until it returns `true`
* {Sink,Source}ManagerBuilder and similars are not actually generic, they *have*
  a generic function.
* how are plugins loaded and how are they specified: automatically if possible

Later on:
* Automatically search plugins, maybe $TREMORPATH
* Check all functions are exported in the plugin
* Make sure a plugin crash doesn't crash Tremor itself if possible. Can panics
  be caught?
* Check conflicting plugin names
////

First of all, Tremor is an event processing system for unstructured data. One of
its many usages may be to:

. Receive logs from different applications in your business
. Filter, transform, and mix them up following the same structure
. Send all the now structured logs to your database

image::/blog/plugin-dynload/example.png[width=100%]

This currently works with
https://www.tremor.rs/docs/artefacts/onramps/[onramps],
https://www.tremor.rs/docs/artefacts/offramps/[offramps] and pipelines:

* A pipeline is a set of operations (transformation, aggregation, dropping, etc)
  through which events can be routed.
* An onramp specifies how Tremor connects to the outside world (or pipeline) in
  order to *receive from external systems*, such as
  https://www.tremor.rs/docs/artefacts/onramps/#tcp[TCP],
  https://www.tremor.rs/docs/artefacts/onramps/#metronome[periodically] or
  https://www.tremor.rs/docs/artefacts/onramps/#postgresql[PostgreSQL].
* An offramp specifies how Tremor connects to the outside world (or pipeline) in
  order to *publish to external systems*, such as
  https://www.tremor.rs/docs/artefacts/offramps/#stdout[stdout],
  https://www.tremor.rs/docs/artefacts/offramps/#kafka[Kafka] or
  https://www.tremor.rs/docs/artefacts/offramps/#elastic[ElasticSearch].

The thing is that some onramps may not only want to receive from external
systems, but also respond to them directly, acting like an offramp, and
vice-versa. This is currently implemented with what's called
https://www.tremor.rs/docs/operations/linked-transports/["`linked transports`"],
and it's specifically useful for some onramps and offramps like REST and
websocket, where the protocol already provides facility for responding to events
with a single connection.

Basically,
https://github.com/tremor-rs/tremor-rfcs/blob/connectors-n-streams/text/0000-connectors-streams.md[connectors]
are just a way to abstract over both onramps and offramps under the same
concept, including linked transports. As the time of writing this article
they're still being implemented by Matthias in the
https://github.com/tremor-rs/tremor-runtime/tree/connectors[`connectors` branch]
of https://github.com/tremor-rs/tremor-runtime[tremor-rs/tremor-runtime], but
their interface, defined with the
https://github.com/tremor-rs/tremor-runtime/blob/883f13e29b4c6ec7b6703f2487aac321c738e7c8/src/connectors.rs#L739[`Connector`
trait], is somewhat stable.

After the interface is done, we could implement the two following connector
plugins:

* https://github.com/tremor-rs/tremor-runtime/blob/main/src/sink/blackhole.rs[Blackhole]
  is used for benchmarking. It takes measurements of the end to end times of each
  event traversing the pipeline and at the end prints an HDR (High Dynamic
  Range) http://hdrhistogram.org/[histogram].
* https://github.com/tremor-rs/tremor-runtime/blob/main/src/source/blaster.rs[Blaster]
  replays a series of events specified in a file, which is specially useful for
  performance testing.

Both of these are relatively simple and will be helpful to benchmark the PDK
later on. But that isn't really important right now; we first need to get the
PDK working, and then we can care about performance.

We will have to keep the plugin interface as simple as possible. We don't need
to run multiple connectors at the same time, and we should keep the
communication details to the runtime. The plugin can be simplified so that it
just exports a number of synchronous functions. With this we can avoid passing
some complex types (`async`, channels, etc) between the runtime and plugin,
which can be impossible if you have to maintain ABI stability (`abi_stable`
doesn't even support `async`).

Once this lean plugin interface is defined, we can create some kind of wrapper
in the runtime (a _manager_, in Tremor terms) that handles all of this. This
exact same thing is done by other crates such as {{< crate rdkafka >}}, which is
based on the C library {{< crate rdkafka-sys >}}, and implements the
asynchronous interface on top of it.

== About Tremor

As always, these articles include a first section with content specific to
Tremor that you might <<actual_start,want to skip>>. Unfortunately, with time
this series will become more and more specific to Tremor; after all I'm just
reporting my progress on their PDK. Still, having a step-by-step walkthrough for
a real-life Plugin System will surely be helpful to those attempting to do the
same.

=== My next steps

In the first meeting we discussed the work I had exposed in my last update.
Despite the complications (being forced to use {repr-c}), the team liked where
the PDK was going.

They suggested me to start with connectors for the real-life example, even
though they were incomplete because Matthias was still working on them. The best
way to do this would be to copy the bare minimum from
https://github.com/tremor-rs/tremor-runtime[Tremor's repository] and try to get
the simplest Proof of Concept working.

In previous meetings we had discussed the possibility of having generics in the
interface, but that turned out to not be necessary at all. The `Connector`
trait had a workaround to avoid generics with `SinkManagerBuilder`.

=== On software engineering

At the end of the first meeting, Darach gave some very interesting advice for my
software engineering career, so I took note of it and reflected for a bit:

* As you get more experience in the field, you talk more and code less. The
  positions you're in become more about team management than programming. It's
  good to remember that software engineering isn't just coding. Also that with
  time, your personality changes, and you have to keep adapting.
* Team building isn't about getting a group of people to carry the exact same
  tasks in the same way. Everyone is different; you'll have to discover the
  strengths and weaknesses of each member and figure out how to mix them up. The
  best teams are often very heterogeneous, and it's pretty clear to me that this
  is the case with Tremor as well.
* Don't care about what others say about you (the _don't worry_ rule). Don't let
  "`You'll never end up being X`", "`You're bad at Y`" and similars ever affect
  you.
* Coding is mentally exhausting and burnout is a very common thing. Take good
  rest, breathe, and have fun. Taking a break from programming is a good idea
  from time to time.
+
I've personally experienced burnout myself so I know this first hand. You may
immerse yourself too much in computers or coding (specially under a pandemic
that restricts how much you can go out). Finding a hobby outside of that is
incredibly helpful.

////
2021-09-07 MEETING NOTES:

* start with connectors, don't worry that much b/c the real overhead lies in the
  external dependencies (networking/etc)
* copy stuff from connectors branch into new repo, forget everything else
  https://github.com/tremor-rs/tremor-runtime/blob/main/src/source/blaster.rs
  https://github.com/tremor-rs/tremor-runtime/blob/main/src/sink/blackhole.rs
* try to see if generics are avoidable
* benchmarks:

  cd tremor-cli
  tremor test bench tests
  
  (or)

  ./bench/run.sh <name>
* start async with callbacks for example instead of something more complicated
* for async take a look at how libkafka does it:
  https://github.com/fede1024/rust-rdkafka


* in team building, everyone is different and the team is very homogeneous, you
  have to figure out how to mix them up
* as you get older you talk more and code less
* remember that with time you change, and so does your position in the company
  (developing people instead of code)
* don't care about what others say about you (don't worry)
* take good rest, breathe, coding is mentally exhausting
////

=== How Tremor works

After starting to write the PDK example for connectors and failing because I
didn't know what I was doing, I decided to step back and try to understand in
detail how Tremor works. Once I had that covered, I could try to simplify the
PDK as much as possible in order to keep my sanity.

I jumped into the codebase of
https://github.com/tremor-rs/tremor-runtime[`tremor/tremor-runtime`] and tried
to figure out how it was structured, also with the help of the team later on.
First of all: Tremor is loosely based on the actor model. Quoting Wikipedia:

[quote, 'https://en.wikipedia.org/wiki/Actor_model[Actor model, Wikipedia]']
____
[The actor model treats the] actor as the universal primitive of concurrent
computation. In response to a message it receives, an actor can: make local
decisions, create more actors, send more messages, and determine how to respond
to the next message received. Actors may modify their own private state, but can
only affect each other indirectly through messaging (removing the need for
lock-based synchronization). 
____

It doesn't use a language (e.g. Erlang) or framework (e.g. {{< crate bastion
>}}, maybe in the future) that strictly follows the actor model, but it often
re-implements the same patterns manually. Tremor is currently implemented with
https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)[asynchronous
programming], which means that instead of threads we'll be working with _tasks_,
a higher level concept. From the {{< crate async-std >}} documentation:

[quote, 'https://docs.rs/async-std/1.10.0/async_std/task/index.html[`async_std::task`], docs.rs']
____
An executing asynchronous Rust program consists of a collection of native OS
threads, on top of which multiple stackless coroutines are multiplexed. We refer
to these as “tasks”. Tasks can be named, and provide some built-in support for
synchronization.
____

We could summarize this with the sentence "`Tremor is based on actors running in
separate tasks which communicate asynchronously via channels`". The main actor
is called the `World`. It contains the state of the program, such as the
available artifacts (_repositories_) and the running ones (_registries_), and
it's used to initialize and control the program.

I'll try to follow what Tremor does in order to get a connector running with the
help of a few diagrams. The following diagram showcases what happens when a
`World` is created. This introduces the concept of _Managers_, which simply are
actors in the system that wrap up some functionality.

Managers help decouple the communication and the implementation of the
underlying functionality. They are also useful to remove some boilerplate when
initializing the components, such as creating the communication channel or
spawning the component in a separate task.

Generally, there's one manager per artefact type, which helps with their
initialization process, and then there's one manager per running instance,
handling their communication details.

image::/blog/plugin-dynload/registering.png[width = 100%]

Once all the managers are initialized, Tremor currently registers all the
built-in artifacts in a "`hardcoded`" way with `register_builtin_types`. But
after the PDK is implemented, this will happen dynamically, i.e. Tremor will
automatically look for DLL/SO files in its configured directory and try to
register all the plugins it can find. The user may additionally request a
specific plugin to be loaded while Tremor is running.

Note that the initialization of the connectors is done in two steps: first
they're _registered_, which just means that the connector is now available for
loading (they're added to the _repository_). The connector doesn't actually
start running until a binding is created with it, for example with
`launch_binding`, which will remove it from the repository and add it to the
_registry_, with the currently running artifacts.

`connectors::Manager` contains all the connectors running in Tremor, which we'll
now try to understand:

image::/blog/plugin-dynload/initializing.png[width = 100%]

Since it's a multi-step process (it's actually more complicated than
registration + creation), the first part of it already provides the tools to
initialize the connector (mainly the builder). When the connector needs to start
running because it's been added to a binding in the pipeline, the builder helps
to construct it generically with the previously provided configuration details.
Finally, it's moved into a task of its own, so that it may communicate with
other parts of Tremor.

Now that we have a connector running, let's see how it's split up into the
source and sink parts. In a very similar way, a builder is used to initialize
the underlying source, sink, or both, and then a new task is spawned for them.

A manager is also created for each instance of source/sink, which will handle
the communication with other actors. This way, the source and sink interfaces
can be kept as simple as possible. These managers will receive connection
requests from the pipeline and then redirect or read from it.

The main difference between sinks and sources currently is that the former can
also reply to messages within the same connection. This is useful to acknowledge
the package ("`Ack`") or to notify something has failed in the sink ("`Fail`"
for a specific event, "`CircutBreaker`" to completely stop data from being
sent).

image::/blog/plugin-dynload/setting-up.png[width = 100%]

Some connectors are based on _streams_. They are equivalent for example to TCP
streams, which help to group up messages and avoid mixing them up. They are
manually started and ended via messages, and the manager saves their state in a
field called `states` (since for instance preprocessors may need to keep a
state). If a connector doesn't need this, such as the `metronome`, it may simply
specify `DEFAULT_STREAM_ID` as the stream ID always.

Codecs and preprocessors are involved here both at the source and sink levels.
In the source part, the data is transformed or split up through a chain of
preprocessors and then the codec is applied. For the sinks, the inverse process
is followed: the data is first encoded into bytes with the codec, and then a
series of post-processors are applied to the raw binary data.

[[actual_start]]
== Taking a look at eBPF first

In the previous articles I mostly considered using either WebAssembly or Dynamic
Loading. What I didn't even know about is https://ebpf.io/[eBPF], "`a
revolutionary technology with origins in the Linux kernel that can run sandboxed
programs in an operating system kernel`". However, similarly to WebAssembly, its
usage has been expanded to user-space applications. eBPF defines a set of
bytecode instructions that may be ran by a virtual machine anywhere, similarly
to how Wasm works.

There are multiple active crates for eBPF in Rust. {{< crate libbpf_rs >}}, {{<
crate redbpf >}} and {{< crate aya >}} are specific to the Linux Kernel. {{<
crate solana_rbpf >}} is a virtual machine, so it only works for user-space. The
maintainers of the latter use it to https://solana.com/[safely run apps on the
blockchain], and their crate seems to be a fork of the now abandoned (?) {{<
crate rbpf >}}. https://www.youtube.com/watch?v=xj0PBFjLm1U&t=8701s[This recent
talk at LPC 2021] explains the situation of eBPF in Rust quite well (mainly for
Aya, so it's mostly related to the Linux Kernel).

Unlike WebAssembly, you don't necessarily need to serialize or write to an
intermediate memory. Since you fully control how the virtual machine works, the
runtime could implement a custom sandbox that simply checks for the read/written
addresses in the plugins to make sure they aren't out of bounds, while still
sharing the same memory space. So in terms of performance, Tremor itself _could_
use it -- though there's still the penalty of interpreting plugins.

The problem in this case is that, for what I've found, Rust support leaves to be
desired. Most people seem to use C for eBPF and I think it shows; the number of
tutorials/guides/articles about eBPF on Rust is incredibly small. There's no
official target to compile Rust to eBPF, and the only user-space runtime we can
use is `rbpf` and its derivatives. Looking for information about this topic was
somewhat frustrating, specially because the search results are mixed up with
kernel-only BPF, which is not relevant to us.

It doesn't really seem like the best choice right now. We would have to write
almost everything about the plugin system from scratch, including the sandbox
itself (allowing only different sets of syscalls, bounds checking, etc). It
would be considerably more cumbersome than using something like `abi_stable`.
Maybe in the future it'd be worth trying it out in detail and running some
benchmarks, but for now I think dynamic loading is still the clear winner.

Cheers to Dr. Florentin Rochet for letting me know about this technology --
though he's considering switching to WebAssembly. He's currently using it to
research _pluggable_ anonymous protocols like Tor, which would allow patches to
their code to happen at runtime <<florentin-1>> <<florentin-2>> <<florentin-3>>
<<florentin-4>>. This makes it faster to fix vulnerabilities until it's properly
updated upstream, among other things. Pretty cool :)

== Trying raw dynamic linking

Now that we definitely know how to approach the PDK, we have two choices: using
raw dynamic linking with the C ABI, or trying out the `stable_abi` crate. I
suggest we do both. We'll most likely end up using the latter because it should
be easier and safer, but it's still a very good idea to know how `stable_abi`
works under the hood.

In the previous article I created a `dynamic-simple` experiment in examples to
https://github.com/marioortizmanero/pdk-experiments[the pdk-experiments
repository]. In this one we'll try to get an implementation that's closer to
what we need for connectors, so we'll call the new experiment
`dynamic-connectors`.

=== Versioning

In order to get more advanced things running, we should figure out how to
properly embed metadata in the plugin. In order to export any type, we already
know that it must be FFI-safe. But there's something else of great importance:
versioning. In order to safely load the plugin, one must ensure that the
versions of the `common` crate match -- or at least that they're compatible --
for both the runtime and the plugin. Here's an example of how this could go
wrong if we don't save information about versioning:

.Plugin implementation
[source, rust]
----
// This is the declaration for the plugin data in version 0.1
#[repr(C)]
pub struct PluginData {
    pub name: &'static [u8],
    pub new: unsafe extern "C" fn() -> State,
}

#[no_mangle]
pub static PLUGIN_DATA: PluginData = PluginData { name: b"test", new };
----

.Runtime implementation
[source, rust]
----
// And this is the same type, but in version 0.2
#[repr(C)]
struct PluginData {
    pub name: &[u8],
    pub new: unsafe extern "C" fn() -> State,
    // NOTE: this field is new here!
    pub connect: unsafe extern "C" fn(&mut State) -> bool
}

fn main() -> Result<(), anyhow::Error> {
    unsafe {
        let library = Library::new(path)?;

        let data = library
            .get::<*const PluginData>(b"PLUGIN_DATA")?
            .read(); // !!! UNDEFINED BEHAVIOUR !!! What will `data.connect` be?
    }

    Ok(())
}
----

In the code above, we can see that, even though both versions of `PluginData`
are FFI-safe, their layouts aren't the same, because the last one has a new
field. When trying to read `PLUGIN_DATA`, undefined behaviour will occur (most
likely accessing to an invalid memory address).

Every plugin should export the version of `common` it uses, and the runtime
should check it before anything else. In summary, the type used for the version
has to be:

* *FFI-safe*, so `&str` or `CStr` are discarded (the latter is a Rust wrapper and
  not {repr-c}).
* *Stable*. `abi_stable::Rstr` won't work either because the versions for
  `abi_stable` might mismatch as well, since we're reading the symbol before
  knowing that. Its layout must be always the same.
* *Thread-safe* (implement `Sync`). If we wanted to use something like `*const
  c_char`, the compiler would throw the following error, since it's a pointer:
+
[source, text]
----
error[E0277]: `*const i8` cannot be shared between threads safely
 --> src/lib.rs:4:1
  |
4 | pub static VERSION: *const c_char = b"0.1.0\0".as_ptr() as _;
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `*const i8` cannot be shared between threads safely
  |
  = help: the trait `Sync` is not implemented for `*const i8`
  = note: shared static variables must have a type that implements `Sync`
----
+
Instead, we can use a function that returns the string:
+
[source, rust]
----
#[no_mangle]
pub extern "C" fn get_version() -> *const c_char {
    b"0.1.0\0".as_ptr() as _
}
----

Finally, there are multiple ways to handle versioning in the runtime, depending
on how fine-grained (but also more error-prone) it should be:

* The simplest way possible: both version strings must be the same.
* The plugin system could take advantage of https://semver.org/[semantic
  versioning]. Only differences in the major version (X.0.0) would be
  incompatible. The problem in this case is that this is kept track of manually,
  and it's possible that a breaking change is introduced by mistake.
* Since there are actually many kinds of plugins (connectors, codecs, etc),
  rather than checking the version for the entire `common` crate, there could be
  a version _per type of plugin_. If a change in the `common` crate only
  modifies structures for codec plugins, the rest of the plugins would still
  work.

=== Automatically loading plugins

Another complicated topic is plugin distribution and management. In order to
make it easier for the user, plugins should be found and loaded automatically.
But how exactly should this work? I'll explain a few ideas.

First of all, the plugins can be found automatically by searching one or more
user-configurable directories. For instance, in Tremor's case we could use
https://www.tremor.rs/docs/tremor-query/modules#defaults[`TREMOR_PATH`]. Once we
have a list of directories where we should look for plugins there are two ways
to do it:

* Only checking the immediate files in the directory
* Recursively, which is more convenient but might cause issues if the node is
  too deep. If the user specified `/` as a directory, the runtime would most
  likely crash unless we used something efficient like
  https://github.com/sharkdp/fd[`fd`] or added a depth limit.

Once we're traversing a directory, we have to figure out which files are plugins
and which aren't. The easiest way to do it is with file extensions, but this
introduces the problem of cross-compatibility. Dynamic libraries usually have a
different extension name for each Operating System: Windows uses `.dll`, Linux
and FreeBSD use `.so`, and MacOS uses `.dylib`, as specified by
https://doc.rust-lang.org/std/env/consts/constant.DLL_EXTENSION.html[`std::env::consts::DLL_EXTENSION`].
It would make sense that our runtime only tried to load plugins with their
respective extensions.

However, these extensions are just conventions; we could just enforce a single
extension name, as
https://docs.rs/libloading/0.7.0/libloading/struct.Library.html#tips[`libloading`
suggests]. It might be easier if we just used `.module` for everything, for
example.

Additionally, the Tremor plugin system requires that plugins can be loaded _both
at initialization time and at runtime_. There is a decision to be made in here
about how the latter should work:

* Manually: the user would input in some way that a new plugin should be loaded
  (for example with the CLI tool). They could either specify a path in which
  it's saved, or just add it to the configured directories that were checked at
  initialization time, and the runtime would try to find it.
* Automatically: the runtime could detect whenever a new plugin is added to the
  list with a crate like {{< crate notify >}}. Most Operating Systems have some
  way to get a notification whenever a file or directory changes. In case a new
  file was added to any of the configured directories, the runtime could try to
  load it.
* A combination of both: if the directories configured to look for plugins can't
  be changed at runtime it might be interesting to also let the user manually
  load plugins in specific paths.

=== Handling state

Most plugins will want to keep some kind of state between calls to its
interface. For example, the TCP connector will need to keep its socket after the
connection in order to send or receive messages. This means that most of them
will follow the following pattern:

[source, rust]
----
let state = plugin.new();
plugin.something(&mut state);
----

The state is first created with a `new` function that initializes everything as
needed, and then a mutable reference is passed to its functions. The main
problem here is, if each plugin is going to have its own type of state, what's
the function signature of `Plugin::something`, defined in `common`?

==== Generics in plugins?

In a regular Rust project we'd just make `Plugin::something` generic over a
common trait that all states should implement. Unfortunately, generics in
plugins are fundamentally impossible. In Rust, monomorphization turns generic
code into specific code by filling in the concrete types that are used when
*compiled* <<generics>>. Plugins are loaded at runtime, so they may want to use
types the compiler didn't generate code for.

It's really easy to prove in Rust with the following example. We'll try to
_load_ an external function with generics:

[source, rust]
----
extern "C" {
    fn foo<T>(_: T);
}
----

This results in the following error:

[source, text]
----
error[E0044]: foreign items may not have type parameters
 --> src/lib.rs:2:5
  |
2 |     fn foo<T>(_: T);
  |     ^^^^^^^^^^^^^^^^ can't have type parameters
  |
  = help: replace the type parameters with concrete types like `u32`

error: aborting due to previous error

For more information about this error, try `rustc --explain E0044`.
----

Interestingly enough, the compiler lets you export generic functions declared
_in Rust_:

[source, rust]
----
extern fn foo<T>(_: T) {}
----

This confused me in the beginning; it made me think generic functions through
FFI were somehow be possible. But as described in
https://github.com/rust-lang/rust/pull/15831[the original issue that allowed
them], they're only supported to pass callbacks to C functions.

Do note that generics in plugins do work for lifetimes. This will compile:

[source, rust]
----
extern "C" {
    fn foo<'a>(_: &'a str) -> &'a str;
}
----

That is mainly because even though lifetimes and generics share the same syntax,
in the case of lifetimes they are only annotations for the Rust compiler;
monomorphization is not applied.

==== `dyn` in plugins?

The alternative to generics is often using trait object types with `dyn`. Again,
will that work for plugins? Let's try:

[source, rust]
----
pub trait PluginState {}
pub extern fn foo<T>(_: &dyn PluginState) {}
----

Compiling...

[source, text]
----
warning: `extern` fn uses type `dyn PluginState`, which is not FFI-safe
 --> src/lib.rs:2:25
  |
2 | pub extern fn foo<T>(_: &dyn PluginState) {}
  |                         ^^^^^^^^^^^^^^^^ not FFI-safe
  |
  = note: `#[warn(improper_ctypes_definitions)]` on by default
  = note: trait objects have no C equivalent
----

Nope. `dyn` is strictly part of the Rust ABI, so it's not stable for our plugin
system. Let's try something simpler.

==== The C way

There are two popular ways to approach this in C:

. Globals, but they are hard to deal with in concurrent programs
. `void*`, which is a pointer with no associated type <<void-ptr>>

For safety's sake, let's see how the second one works. This pattern is used for
example in PulseAudio <<pulseaudio-ptr>>, in which callbacks pass a `void*`
parameter for user data. Here's a simpler program:

[source, c]
----
#include <stdio.h>
#include <stdlib.h>

// The state of the plugin
typedef struct {
    int counter;
} plugin_state_t;

// Exported by the plugin, initializes the state
void* new() {
    plugin_state_t* plugin_state = malloc(sizeof(plugin_state_t));
    plugin_state->counter = 0;
    return (void*) plugin_state;
}

// Exported by the plugin, which takes a pointer to its state
void something(void* state) {
    // We know the runtime used `new` to initialize the state, so we can cast it
    // back to its original type.
    plugin_state_t* plugin_state = (plugin_state_t*) state;

    printf("Current state: { counter = %d }\n", plugin_state->counter);
    plugin_state->counter++;
    printf("Final state: { counter = %d }\n", plugin_state->counter);
}

int main() {
    // We initialize the plugin, which returns its state
    void* state = new();
    // When calling anything from the plugin we pass its state
    something(state);
    // Don't forget!
    free(state);
}
----

This does work perfectly, and we could port it to Rust as a straightforward
solution. However, it has the following inconvenients:

* It's very `unsafe`. We'd need to add some kind of wrapper/macro on the plugin
  side to avoid invoking undefined behaviour.
* We know nothing about the state. A `void*` can't enforce `Debug` being
  implemented, nor any other method or trait that might be of interest to us.

Based on how this works, we can try to extend it by implementing
intheritance-based polymorphism manually.
https://adventures.michaelfbryan.com/posts/ffi-safe-polymorphism-in-rust/[This
blog post by Michael
F. Bryan's] covers the topic extremely well.

Here's how our previous example would look like, which would absolutely work in
Rust:

[source, c]
----
#include <stdio.h>
#include <stdlib.h>

// The base plugin type
typedef struct base_state_t {
    void (*print)(struct base_state_t *);
} base_state_t;

// The state of the plugin, child of the above type
typedef struct {
    base_state_t base;
    int counter;
} plugin_state_t;

// The implementation of `print` for the `plugin_state_t` child
void print(base_state_t* state) {
    plugin_state_t* plugin_state = (plugin_state_t*) state;
    printf("Current state: { counter = %d }\n", plugin_state->counter);
}

// Exported by the plugin, initializes the state
base_state_t* new() {
    base_state_t base = {print};

    plugin_state_t* plugin_state = malloc(sizeof(plugin_state_t));
    plugin_state->base = base;
    plugin_state->counter = 0;
    return (base_state_t*) plugin_state;
}

// Exported by the plugin, which takes a pointer to its state
void something(void* state) {
    // We know the runtime used `new` to initialize the state, so we can cast it
    // back to its original type.
    plugin_state_t* plugin_state = (plugin_state_t*) state;
    plugin_state->counter++;
}

int main() {
    // We initialize the plugin, which returns its state
    base_state_t* state = new();
    // When calling anything from the plugin we pass its state
    state->print(state);
    something((void*) state);
    state->print(state);
    // Don't forget!
    free(state);
}
----

The main difference in the code is the new base class `plugin_base_t`. It
defines a single function `print` that should be implemented by its children,
and it could also include other fields that would be inherited. Casting between
`base_state_t` and `plugin_base_t` is sound because it's the first member in the
struct, so it's allowed by the C standard.

This covers all of our necessities. The only remaining problem is that it's
still quite unsafe to use. This can be improved by using the crate {{< crate
thin_trait_object >}}:

[source, rust]
----
#[thin_trait_object]
trait 
----

////
https://adventures.michaelfbryan.com/posts/ffi-safe-polymorphism-in-rust/
https://www.youtube.com/watch?v=xcygqF5LVmM&feature=emb_title

https://docs.rs/thin_trait_object/1.1.2//
////

=== Writing the example

The example at X approaches the topics covered in this section in the simplest
of ways.

=== Error handling

== Moving to `abi_stable`

=== Versioning

=== Handling state

=== Automatically loading plugins

== Adding dynamic loading to the example

In order to safely load the plugin, one must ensure that the versions of the
`common` crate match for both the runtime and the plugin, so we have to save it
somewhere in the metadata of the plugin. However, there's a catch: its layout
must not only be FFI-safe but also fully backward-compatible. For example, we
can't just to export the version with `abi_stable::RStr` and then use
`libloading` to import it. There might be a version mismatch of `abi_stable`
between the crate and the plugin, and since this happens _before_ making sure
they're compatible, their layouts might be different.

[quote, 'https://github.com/rodrimati1992/abi_stable_crates#safety[`abi_stable` README]']
____
This library ensures that the loaded libraries are safe to use through these
mechanisms:

* The abi_stable ABI of the library is checked, Each `0.y.0` version and `x.0.0`
  version of abi_stable defines its own ABI which is incompatible with previous
  versions.
* Types are recursively checked when the dynamic library is loaded, before any
  function can be called.
____

To prove this, let's write the `dynamic-abi-stable` experiment, which follows
the higher-level dynamic loading procedure established by `abi_stable`, instead
of using raw {repr-c} and `libloading`. `abi_stable` provides utilities to load
plugins with no `unsafe` at all, and with versioning and other goodies built-in.
We can take a look at the
https://github.com/rodrimati1992/abi_stable_crates/tree/master/examples[examples]
in order to make it easier.

`abi_stable` plugins are structured in modules, which can help us split up our
functionality into smaller independent pieces. There must always be a
https://docs.rs/abi_stable/latest/abi_stable/library/trait.RootModule.html[root
module] that initializes the entire library. We'll just call it `MinMod` and
implement the `min` function:

[source, rust]
----
// todo copy stuff from exp
----

https://docs.rs/abi_stable/0.10.2/abi_stable/derive.StableAbi.html

In order to make it easier for the plugin developer, we can create the macro
`define_plugin`:

== Setting up cbindgen

For the first steps with dynamic loading I think {{< crate cbindgen >}} will
help us understand what's going on. We can take a look at the generated headers
and see how it works internally. Unfortunately, it fails to run for the
`abi_stable` crate:

[source, text]
----
(...)
WARN: Skip abi_stable::CONST - (...)
 
thread 'main' panicked at 'RResult has 2 params but is being instantiated with 1 values', src/bindgen/ir/enumeration.rs:596:9
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
----

This _probably_ has to do with the following warning found in
https://github.com/eqrion/cbindgen/blob/master/docs.md[``cbindgen``'s
documentation]:

____
pass:[NOTE:] A major limitation of cbindgen is that it does not understand
Rust's module system or namespacing. This means that if cbindgen sees that it
needs the definition for `MyType` and there exists two things in your project
with the type name `MyType`, it won't know what to do. Currently, cbindgen's
behaviour is unspecified if this happens. However this may be ok if they have
https://github.com/eqrion/cbindgen/blob/master/docs.md#defines-and-cfgs[different
cfgs].
____

After letting the maintainers of `abi_stable` know about this in
https://github.com/rodrimati1992/abi_stable_crates/issues/52[an issue], they
pointed out that this was expected and that they don't plan on supporting
`cbindgen` because it would take too much effort. Understandable, so let's move
on.

== Error Handling

I also wanted to create some experiments about error handling in the PDK. Since
in the end we aren't using a sandbox, I wonder what kind of errors we _can't_
recover from. We should treat these cases with care in order to avoid them at
all costs.

I've written the following plugins for now:

=== Missing field

The `plugin-missing` directory is an empty plugin. It doesn't export any fields
at all, like the name or the version. This one is already handled by
`libloading`, actually. When using `library.get("name")`, if `"name"` is
unavailable in the shared object, the following error will show up:

[source, text]
----
$ make debug-missing
Error when setting up the plugin: plugin-missing/target/debug/libplugin_missing.so: undefined symbol: get_name
----

=== Version mismatch

[source, text]
----
$ make debug-versionmismatch
Initializing plugin versionmismatch
Version mismatch. Aborting.
Error when setting up the plugin: version mismatch: 0.0.0 incompatible with 0.1.0
----

=== Wrong type

[source, text]
----
$ make debug-wrongtype
Segmentation fault (core dumped)
----

=== Wrong address

[source, text]
----
$ make debug-wrongaddress
Segmentation fault (core dumped)
----

== Conversions to `abi_stable`

It's important to know the complexity of conversions from/to `abi_stable` types.
If `std::Vec` -> `abi_stable::RVec` wasn't stem:[O(n)] it might be worth using
only the latter throughout the entirety of Tremor.

This means that I should spend at least a bit of my time on understanding how
the `abi_stable` types are implemented and making sure this isn't the case. In
`std`, the definition of `Vec` is actually quite simple if we remove most of the
noise:

[source, rust]
----
// A non-null pointer to `T` that indicates ownership.
pub struct Unique<T: ?Sized> {
    pointer: *const T, // The data itself
    _marker: PhantomData<T>, // Indicating that we own a `T`
}

// Low level type related to allocation
pub struct RawVec<T> {
    ptr: Unique<T>,
    cap: usize,
}

pub struct Vec<T> {
    buf: RawVec<T>,
    len: usize,
}
----

It's mostly self-explanatory; a `Vec<T>` is a pointer to `T` with a set capacity
and length. What about ``abi_stable``'s implementation?

[source, rust]
----
#[repr(C)] // Notice this, so that it's FFI-safe
#[derive(StableAbi)] // This trait marks `RVec` as FFI-safe, with info about its layout
pub struct RVec<T> {
    pub(super) buffer: *mut T,
    pub(super) length: usize,
    capacity: usize,
    vtable: VecVTable_Ref<T>,
    _marker: PhantomData<T>,
}
----

Yup, basically the same, but packed inside a single struct. The only real
difference is that we have a field with the vtable, which I'll cover later on.
The conversion between these types is written with a macro, but if expanded, it
looks like this:

[source, rust]
----
impl<T> From<Vec<T>> for RVec<T> {
    fn from(this: Vec<T>) -> RVec<T> {
        let mut this = std::mem::ManuallyDrop::new(this);
        RVec {
            vtable: VTableGetter::<T>::LIB_VTABLE,
            buffer: this.as_mut_ptr(),
            length: this.len(),
            capacity: this.capacity(),
            _marker: PhantomData,
        }
    }
}
----

The only "`weird`" part is the usage of `std::mem::ManuallyDrop`, which simply
is a wrapper that indicates Rust to not call the destructor of its contents
automatically. In this case it's basically a less error prone
`std::mem::forget`, as
https://doc.rust-lang.org/stable/std/mem/fn.forget.html#relationship-with-manuallydrop[its
docs explain]. Thanks to it, the memory from the vector won't be dropped when
this function ends, and it can be safely moved into the `RVec`, with no copying.

This happens for every type I checked in `abi_stable`, including `RSlice<T>`,
which contains a reference to a slice, `RStr`, which is just a `RSlice<u8>`, and
`RString`, which is just a `RVec`.

== Panicking

`abi_stable` can't do anything about the unsafety of panicking in plugins. It
will simply abort the program:

[source]
----
Loading plugin min
initial state: State { counter: 0 }
thread '<unnamed>' panicked at 'This will crash everything', src/lib.rs:26:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

file:src/lib.rs
line:24
Attempted to panic across the ffi boundary.
Aborting to handle the panic...
----

== Thread safety

== Setting Up Miri

== Tremor connectors

Since it may be simpler to get `native-connector` running, let's start with
that. We'll just copy all the necessary code for the
https://github.com/tremor-rs/tremor-runtime/tree/883f13e29b4c6ec7b6703f2487aac321c738e7c8[current
implementation] of connectors as a standalone program:

== Conclusion

////
== Benchmarking

I've always wanted to run some benchmarks in order to find out the actual
difference in performance between dynamic loading (with native code) and Wasm
(with interpreted code). Of course, the former will be faster. But, is it
noticeable?

TODO compare with already existing benchmarks, what to expect, etc

Now that I have some examples of both dynamic loading and Wasm plugins, I can
make a few benchmarks in order to see the difference by myself. The `wasm-bench`
and `dynamic-bench` directories in
https://github.com/marioortizmanero/pdk-experiments[pdk-experiments] can be
compiled and then ran with
https://doc.rust-lang.org/1.7.0/book/benchmark-tests.html[Rust's integrated
benchmarking system] (which requires nightly for now)
////

[bibliography]
== References

- [[[florentin-1,     1]]] https://pluginized-protocols.org/
- [[[florentin-2,     2]]] https://pquic.org/
- [[[florentin-3,     3]]] https://petsymposium.org/2019/files/hotpets/proposals/rochet-fan.pdf
- [[[florentin-4,     4]]] https://petsymposium.org/2019/files/hotpets/slides/rochet-fan-slides.pdf
- [[[void-ptr,       11]]] https://www.learncpp.com/cpp-tutorial/void-pointers/
- [[[pulseaudio-ptr, 11]]] https://freedesktop.org/software/pulseaudio/doxygen/stream_8h.html#a2dcc985c65964da290a0c2e1bf103175
- [[[generics,       11]]] https://doc.rust-lang.org/book/ch10-01-syntax.html#performance-of-code-using-generics
