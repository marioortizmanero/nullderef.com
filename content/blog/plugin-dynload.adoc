---
title: "Plugins in Rust: Diving into dynamic loading"
description: "A closer look at dynamic loading in Rust"
summary: "Writing a more advanced example of dynamic loading working, and
analyzing the results."
author: "Mario Ortiz Manero"
tags: ["rust", "journal"]
series: ["rust-plugins"]
date: 2021-09-09
GHissueID: ??
---

:sectnums:

:repr-c: pass:quotes[`#[repr\(C)]`]

== Introduction

In the https://nullderef.com/blog/plugin-start/[last part] of this
https://nullderef.com/series/rust-plugins/[series] I wrote some simple
experiments of plugins both with WebAssembly and dynamic loading. After
discarding Wasm for this specific PDK, I wanted to try to get a more realistic
example with dynamic loading and work towards the final implementation.

As always, these articles include a first section with content specific to
Tremor that you might <<actual_start,want to skip>>. Unfortunately, with time
this series will become more and more specific to Tremor; after all I'm just
reporting my progress on their PDK. Still, having a step-by-step walkthrough for
a real-life Plugin System will surely be helpful to those attempting to do the
same.

== About Tremor

=== My next steps

In the first meeting we discussed the work I had exposed in my last update.
Despite the complications (being forced to use {repr-c}), the team liked where
the PDK was going.

They suggested me to start with connectors for the real-life example, even
though they were incomplete because Matthias was still working on them. The best
way to do this would be to copy the bare minimum from
https://github.com/tremor-rs/tremor-runtime[Tremor's repository] and try to get
the simplest Proof of Concept working.

In previous meetings we had discussed the possibility of having generics in the
interface, but that turned out to not be necessary at all. The `Connector`
trait had a workaround to avoid generics with `SinkManagerBuilder`.

=== On software engineering

At the end of the first meeting, Darach gave some very interesting advice for my
software engineering career, so I took note of it and reflected for a bit:

* As you get more experience in the field, you talk more and code less. The
  positions you're in become more about team management than programming. It's
  good to remember that software engineering isn't just coding. Also that with
  time, your personality changes, and you have to keep adapting.
* Team building isn't about getting a group of people to carry the exact same
  tasks in the same way. Everyone is different; you'll have to discover the
  strengths and weaknesses of each member and figure out how to mix them up. The
  best teams are often very heterogeneous, and it's pretty clear to me that this
  is the case with Tremor as well.
* Don't care about what others say about you (the _don't worry_ rule). Don't let
  "`You'll never end up being X`", "`You're bad at Y`" and similars ever affect
  you.
* Coding is mentally exhausting and burnout is a very common thing. Take good
  rest, breathe, and have fun. Taking a break from programming is a good idea
  from time to time.
+
I've personally experienced burnout myself so I know this first hand. You may
immerse yourself too much in computers or coding (specially under a pandemic
that restricts how much you can go out). Finding a hobby outside of that is
incredibly helpful.

////
2021-09-07 MEETING NOTES:

* start with connectors, don't worry that much b/c the real overhead lies in the
  external dependencies (networking/etc)
* copy stuff from connectors branch into new repo, forget everything else
  https://github.com/tremor-rs/tremor-runtime/blob/main/src/source/blaster.rs
  https://github.com/tremor-rs/tremor-runtime/blob/main/src/sink/blackhole.rs
* try to see if generics are avoidable
* benchmarks:

  cd tremor-cli
  tremor test bench tests
  
  (or)

  ./bench/run.sh <name>
* start async with callbacks for example instead of something more complicated
* for async take a look at how libkafka does it:
  https://github.com/fede1024/rust-rdkafka


* in team building, everyone is different and the team is very homogeneous, you
  have to figure out how to mix them up
* as you get older you talk more and code less
* remember that with time you change, and so does your position in the company
  (developing people instead of code)
* don't care about what others say about you (don't worry)
* take good rest, breathe, coding is mentally exhausting
////

[[actual_start]]
== Taking a look at eBPF first

In the previous articles I mostly considered using either WebAssembly or Dynamic
Loading. What I didn't even know about is https://ebpf.io/[eBPF], "`a
revolutionary technology with origins in the Linux kernel that can run sandboxed
programs in an operating system kernel`". However, similarly to WebAssembly, its
usage has been expanded to user-space applications. eBPF defines a set of
bytecode instructions that may be ran by a virtual machine anywhere, similarly
to how Wasm works.

There are multiple active crates for eBPF in Rust. {{< crate libbpf_rs >}}, {{<
crate redbpf >}} and {{< crate aya >}} are specific to the Linux Kernel. {{<
crate solana_rbpf >}} is a virtual machine, so it only works for user-space. It
seems to be a fork of the now abandoned {{< crate rbpf >}}.

So, is this any better than WebAssembly? Well, not really. In fact, it has the
same exact caveat that made us discard Wasm; for more complex types, one has to
serialize them into a shared memory. It also has a few more restrictions like
only being able to export one function per file or managing imports or exports
manually within the runtime. You can get started quickly with
https://blog.redsift.com/labs/writing-bpf-code-in-rust/[this tutorial from Red
Sift], but I feel like there's less documentation than in the case of Wasm.

Cheers to Dr. TODO for letting me know about this technology -- though he's
considering switching to WebAssembly. He's currently using it to research
pluggable anonymous protocols like Tor, which would allow patches to its code to
happen at runtime. This makes it faster to fix vulnerabilities until it's
properly updated upstream, among other things. TODO add links. Pretty cool :)

== Extending our example

Since the Tremor team suggested to begin by implementing connectors, we'll first
have to learn more about them. Matthias ran me through their current state in a
meeting, which I'll try to summarize:

=== Learning more about connectors

////
2021-09-07 MEETING NOTES (CONNECTORS):

Connector trait:
* can contain a source, a sink, or both
* handlers like `on_start`, `on_pause`, etc
* `connect` retries until it returns `true`
* {Sink,Source}ManagerBuilder and similars are not actually generic, they *have*
  a generic function.
* how are plugins loaded and how are they specified: automatically if possible

Later on:
* Automatically search plugins, maybe $TREMORPATH
* Check all functions are exported in the plugin
* Make sure a plugin crash doesn't crash Tremor itself if possible. Can panics
  be caught?
* Check conflicting plugin names
////

First of all, Tremor is an event processing system for unstructured data. For
example, you could use it to:

. Receive logs from different applications in your business
. Filter, transform, and mix them up following the same structure
. Send all the now structured logs to your database

This currently works with https://docs.tremor.rs/artefacts/onramps/[onramps]
and https://docs.tremor.rs/artefacts/offramps/[offramps]:

* An onramp specifies how Tremor connects to the outside world in order to
  *receive from external systems*, such as
  https://docs.tremor.rs/artefacts/onramps/#tcp[TCP],
  https://docs.tremor.rs/artefacts/onramps/#metronome[periodically] or
  https://docs.tremor.rs/artefacts/onramps/#postgresql[PostgreSQL].
* An offramp specifies how Tremor connects to the outside world in order to
  *publish to external systems*, such as
  https://docs.tremor.rs/artefacts/offramps/#stdout[stdout],
  https://docs.tremor.rs/artefacts/offramps/#kafka[Kafka] or
  https://docs.tremor.rs/artefacts/offramps/#elastic[ElasticSearch].

The thing is that some onramps may not only want to receive from external
systems, but also respond to them directly, acting like an offramp, and
vice-versa. This is currently implemented with what's called
https://docs.tremor.rs/operations/linked-transports/["`linked transports`"], and
it's specifically useful for some onramps and offramps like REST and websocket,
where the protocol already provides facility for responding to events with a
single connection.  Thanks to this, Tremor has become a platform for
implementing a wider variety of applications -- think servers, proxies, bridges
etc., and not just ETL-style use cases.

Basically,
https://github.com/tremor-rs/tremor-rfcs/blob/connectors-n-streams/text/0000-connectors-streams.md[connectors]
are just a way to abstract over both onramps and offramps under the same
concept, including linked transports. As the time of writing this article
they're still being implemented by Matthias in the
https://github.com/tremor-rs/tremor-runtime/tree/connectors[`connectors` branch]
of https://github.com/tremor-rs/tremor-runtime[tremor-rs/tremor-runtime], but
their interface, defined with the
https://github.com/tremor-rs/tremor-runtime/blob/883f13e29b4c6ec7b6703f2487aac321c738e7c8/src/connectors.rs#L739[`Connector`
trait], is somewhat stable.

After the interface is done, we could implement the two following connector
plugins:

* https://github.com/tremor-rs/tremor-runtime/blob/main/src/sink/blackhole.rs[Blackhole]
  is used for benchmarking. It takes measurements of the end to end times of each
  event traversing the pipeline and at the end prints an HDR (High Dynamic
  Range) http://hdrhistogram.org/[histogram].
* https://github.com/tremor-rs/tremor-runtime/blob/main/src/source/blaster.rs[Blaster]
  replays a series of events specified in a file, which is specially useful for
  performance testing.

Both of these are relatively simple and will be helpful to benchmark the PDK
later on. But that isn't really important right now; we first need to get the
PDK working, and then we can care about performance.

What would be more complicated is handling `async` with C's ABI. For now I will
try to get it to work in the simplest possible way -- possibly callbacks, and
we'll actually work on it later on. Crates like
https://github.com/fede1024/rust-rdkafka[`libkafka`] do something similar, so I
should take a look.

=== Setting up cbindgen

For these first steps I think {{< crate cbindgen >}} will help us understand
what's going on. We can take a look at the generated headers and see how it
works internally. Unfortunately, it fails to run for the `abi_stable` crate:

[source, text]
----
(...)
WARN: Skip abi_stable::CONST - (...)
 
thread 'main' panicked at 'RResult has 2 params but is being instantiated with 1 values', src/bindgen/ir/enumeration.rs:596:9
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
----

This _probably_ has to do with the following warning found in
https://github.com/eqrion/cbindgen/blob/master/docs.md[`cbindgen`'s
documentation]:

____
pass:[NOTE:] A major limitation of cbindgen is that it does not understand
Rust's module system or namespacing. This means that if cbindgen sees that it
needs the definition for `MyType` and there exists two things in your project
with the type name `MyType`, it won't know what to do. Currently, cbindgen's
behaviour is unspecified if this happens. However this may be ok if they have
https://github.com/eqrion/cbindgen/blob/master/docs.md#defines-and-cfgs[different
cfgs].
____

After letting the maintainers of `abi_stable` know about this in
https://github.com/rodrimati1992/abi_stable_crates/issues/52[an issue], they
pointed out that this was expected and that they don't plan on supporting
`cbindgen` because it would take too much effort. Understandable, so let's move
on.

=== Modifying the `Connector` trait for dynamic loading

Now that we know more or less how to approach the PDK, let's try getting a more
complex example running. The plan is to try to simulate the final implementation
of the PDK so that we can run some benchmarks and analyze the overhead it will
introduce. For this, I'll add the `native-connector` and `dynamic-connector`
examples to https://github.com/marioortizmanero/pdk-experiments[the
pdk-experiments repository]. `native-connector` is simply how it currently
works, in a single static executable, and `dynamic-connector` loads the
connectors dynamically as plugins.

Since it may be simpler to get `native-connector` running, let's start with
that. We'll just copy all the necessary code for the
https://github.com/tremor-rs/tremor-runtime/tree/883f13e29b4c6ec7b6703f2487aac321c738e7c8[current
implementation] of connectors as a standalone program:

==== The `Connector` trait

==== The `Value` struct

== Plugin Architecture

In order to load the plugin, one must ensure that the versions of the `common`
crate match for both the runtime and the plugin. Basic metadata such as
versioning must be defined with fully stable types. For example, we can't use
`abi_stable::RStr` to save the version; there might be a version mismatch of
`abi_stable` between the crate and the plugin, and since this happens *before*
making sure they're compatible, it may not work.

All of this is simplified if the macro `define_plugin` is used:

// TODO: explain macro

For now, the version checks are done for the entire crate for simplicity,
but in the future we can make this more flexible. For instance, if a version
bump in this crate only modifies structures for codec plugins, the rest of
the plugins would still work. This would require versioning each of the
types of plugins and bumping them as they're modified. Note that this is
prone to human errors however, as it's a manual process.

// TODO: research https://github.com/doctorn/obake

There may be helpful crates like {{< crate obake >}}.

We'll keep it simple for now, but by exporting the kind of plugin separately
(instead of having an enum `PluginData::Connector`) we can future-proof this.
This is because if we were to deduce the kind of plugin by matching `PluginData`
but one of the single versions that don't affect us mismatched, it may break, as
the layout of the entire enum would change.

== Error Handling

== Setting Up Miri

== Generics

The traits I was trying to make plugin-compatible in Tremor had some instances
of generics. And they'd only get worse in the future with
https://github.com/rust-lang/rust/issues/44265[GATs] and `async` methods in
traits actually being generic as well (we currently use {{< crate async_trait
>}}).

So, first of all let's cross this one out of the checklist. Can we use generics
in the plugins?

=== Why they are impossible

Well, no, generics in plugins are fundamentally impossible. In Rust,
monomorphization turns generic code into specific code by filling in the
concrete types that are used when *compiled* <<generics>>. Plugins are loaded at
runtime, so they may want to use types the compiler didn't generate code for.

It's really easy to prove in Rust with the following example. We'll try to
_load_ an external function with generics:

[source, rust]
----
extern "C" {
    fn foo<T>(_: T);
}
----

This results in the following error:

[source, text]
----
error[E0044]: foreign items may not have type parameters
 --> src/lib.rs:2:5
  |
2 |     fn foo<T>(_: T);
  |     ^^^^^^^^^^^^^^^^ can't have type parameters
  |
  = help: replace the type parameters with concrete types like `u32`

error: aborting due to previous error

For more information about this error, try `rustc --explain E0044`.
----

Interestingly enough, the compiler lets you export generic functions declared
_in Rust_:

[source, rust]
----
extern fn foo<T>(_: T) {}
----

This confused me in the beginning; it made me think generic functions through
FFI would be possible. But as described in
https://github.com/rust-lang/rust/pull/15831[the original issue that allowed
them], they're only supported to pass callbacks to C functions.

Another interesting thing about generics in plugins is that it does work for
lifetimes. This will compile:

[source, rust]
----
extern "C" {
    fn foo<'a>(_: &'a str) -> &'a str;
}
----

That is mainly because even though lifetimes and generics share the same syntax,
in the case of lifetimes they are only annotations. No new versions of the
function are generated.

=== Alternatives

https://adventures.michaelfbryan.com/posts/ffi-safe-polymorphism-in-rust/[Michael
F. Bryan's blog post about `Box<dyn Trait>`] covers pretty well the different
alternatives we have available. Since we can't use generics, `Box<dyn Trait>` is
what we should be using, which makes polymorphism available at runtime. However,
the ABI for `Box<dyn Trait>` is unstable, as it's written in Rust, so we'll have
to find an equivalent alternative.

////
https://adventures.michaelfbryan.com/posts/ffi-safe-polymorphism-in-rust/
https://www.youtube.com/watch?v=xcygqF5LVmM&feature=emb_title

https://docs.rs/typetag/0.1.7/typetag/
https://docs.rs/serde_traitobject/0.2.7/serde_traitobject/
https://docs.rs/thin_trait_object/1.1.2/thin_trait_object/
////

== Conclusion

////
== Benchmarking

I've always wanted to run some benchmarks in order to find out the actual
difference in performance between dynamic loading (with native code) and Wasm
(with interpreted code). Of course, the former will be faster. But, is it
noticeable?

TODO compare with already existing benchmarks, what to expect, etc

Now that I have some examples of both dynamic loading and Wasm plugins, I can
make a few benchmarks in order to see the difference by myself. The `wasm-bench`
and `dynamic-bench` directories in
https://github.com/marioortizmanero/pdk-experiments[pdk-experiments] can be
compiled and then ran with
https://doc.rust-lang.org/1.7.0/book/benchmark-tests.html[Rust's integrated
benchmarking system] (which requires nightly for now)
////

[bibliography]
== References

- [[[generics,       11]]] https://doc.rust-lang.org/book/ch10-01-syntax.html#performance-of-code-using-generics
