---
title: "Plugins in Rust: Diving into dynamic loading"
description: "A closer look at dynamic loading in Rust"
summary: "Writing a more advanced example of dynamic loading working, and
analyzing the results."
author: "Mario Ortiz Manero"
tags: ["rust", "journal"]
series: ["rust-plugins"]
date: 2021-09-09
GHissueID: ??
---

:sectnums:

:repr-c: pass:quotes[`#[repr\(C)]`]

== Introduction

In the https://nullderef.com/blog/plugin-start/[last part] of this
https://nullderef.com/series/rust-plugins/[series] I wrote some simple
experiments of plugins both with WebAssembly and dynamic loading. After
discarding Wasm for this specific PDK, I wanted to try to get a more realistic
example with dynamic loading and work towards the final implementation.

Since the Tremor team suggested to begin by implementing connectors, we'll first
have to learn more about them. Matthias ran me through their current state in a
meeting, which I'll try to summarize:

== Learning more about connectors

////
2021-09-07 MEETING NOTES (CONNECTORS):

Connector trait:
* can contain a source, a sink, or both
* handlers like `on_start`, `on_pause`, etc
* `connect` retries until it returns `true`
* {Sink,Source}ManagerBuilder and similars are not actually generic, they *have*
  a generic function.
* how are plugins loaded and how are they specified: automatically if possible

Later on:
* Automatically search plugins, maybe $TREMORPATH
* Check all functions are exported in the plugin
* Make sure a plugin crash doesn't crash Tremor itself if possible. Can panics
  be caught?
* Check conflicting plugin names
////

First of all, Tremor is an event processing system for unstructured data. For
example, you could use it to:

. Receive logs from different applications in your business
. Filter, transform, and mix them up following the same structure
. Send all the now structured logs to your database

This currently works with https://www.tremor.rs/docs/artefacts/onramps/[onramps]
and https://www.tremor.rs/docs/artefacts/offramps/[offramps]:

* An onramp specifies how Tremor connects to the outside world in order to
  *receive from external systems*, such as
  https://www.tremor.rs/docs/artefacts/onramps/#tcp[TCP],
  https://www.tremor.rs/docs/artefacts/onramps/#metronome[periodically] or
  https://www.tremor.rs/docs/artefacts/onramps/#postgresql[PostgreSQL].
* An offramp specifies how Tremor connects to the outside world in order to
  *publish to external systems*, such as
  https://www.tremor.rs/docs/artefacts/offramps/#stdout[stdout],
  https://www.tremor.rs/docs/artefacts/offramps/#kafka[Kafka] or
  https://www.tremor.rs/docs/artefacts/offramps/#elastic[ElasticSearch].

The thing is that some onramps may not only want to receive from external
systems, but also respond to them directly, acting like an offramp, and
vice-versa. This is currently implemented with what's called
https://www.tremor.rs/docs/operations/linked-transports/["`linked transports`"],
and it's specifically useful for some onramps and offramps like REST and
websocket, where the protocol already provides facility for responding to events
with a single connection.

Basically,
https://github.com/tremor-rs/tremor-rfcs/blob/connectors-n-streams/text/0000-connectors-streams.md[connectors]
are just a way to abstract over both onramps and offramps under the same
concept, including linked transports. As the time of writing this article
they're still being implemented by Matthias in the
https://github.com/tremor-rs/tremor-runtime/tree/connectors[`connectors` branch]
of https://github.com/tremor-rs/tremor-runtime[tremor-rs/tremor-runtime], but
their interface, defined with the
https://github.com/tremor-rs/tremor-runtime/blob/883f13e29b4c6ec7b6703f2487aac321c738e7c8/src/connectors.rs#L739[`Connector`
trait], is somewhat stable.

After the interface is done, we could implement the two following connector
plugins:

* https://github.com/tremor-rs/tremor-runtime/blob/main/src/sink/blackhole.rs[Blackhole]
  is used for benchmarking. It takes measurements of the end to end times of each
  event traversing the pipeline and at the end prints an HDR (High Dynamic
  Range) http://hdrhistogram.org/[histogram].
* https://github.com/tremor-rs/tremor-runtime/blob/main/src/source/blaster.rs[Blaster]
  replays a series of events specified in a file, which is specially useful for
  performance testing.

Both of these are relatively simple and will be helpful to benchmark the PDK
later on. But that isn't really important right now; we first need to get the
PDK working, and then we can care about performance.

We will have to keep the plugin interface as simple as possible. We don't need
to run multiple connectors at the same time, and we should keep the
communication details to the runtime. The plugin can be simplified so that it
just exports a number of synchronous functions. With this we can avoid passing
some complex types (`async`, channels, etc) between the runtime and plugin,
which can be complicated if you have to maintain ABI stability.

Once this lean plugin interface is defined, we can create some kind of wrapper
in the runtime (a _manager_, in Tremor terms) that handles all of this. This
exact same thing is done by other crates such as {{< crate rdkafka >}}, which is
based on the C library {{< crate rdkafka-sys >}}, and implements the
asynchronous interface on top of it.

== About Tremor

As always, these articles include a first section with content specific to
Tremor that you might <<actual_start,want to skip>>. Unfortunately, with time
this series will become more and more specific to Tremor; after all I'm just
reporting my progress on their PDK. Still, having a step-by-step walkthrough for
a real-life Plugin System will surely be helpful to those attempting to do the
same.

=== My next steps

In the first meeting we discussed the work I had exposed in my last update.
Despite the complications (being forced to use {repr-c}), the team liked where
the PDK was going.

They suggested me to start with connectors for the real-life example, even
though they were incomplete because Matthias was still working on them. The best
way to do this would be to copy the bare minimum from
https://github.com/tremor-rs/tremor-runtime[Tremor's repository] and try to get
the simplest Proof of Concept working.

In previous meetings we had discussed the possibility of having generics in the
interface, but that turned out to not be necessary at all. The `Connector`
trait had a workaround to avoid generics with `SinkManagerBuilder`.

=== On software engineering

At the end of the first meeting, Darach gave some very interesting advice for my
software engineering career, so I took note of it and reflected for a bit:

* As you get more experience in the field, you talk more and code less. The
  positions you're in become more about team management than programming. It's
  good to remember that software engineering isn't just coding. Also that with
  time, your personality changes, and you have to keep adapting.
* Team building isn't about getting a group of people to carry the exact same
  tasks in the same way. Everyone is different; you'll have to discover the
  strengths and weaknesses of each member and figure out how to mix them up. The
  best teams are often very heterogeneous, and it's pretty clear to me that this
  is the case with Tremor as well.
* Don't care about what others say about you (the _don't worry_ rule). Don't let
  "`You'll never end up being X`", "`You're bad at Y`" and similars ever affect
  you.
* Coding is mentally exhausting and burnout is a very common thing. Take good
  rest, breathe, and have fun. Taking a break from programming is a good idea
  from time to time.
+
I've personally experienced burnout myself so I know this first hand. You may
immerse yourself too much in computers or coding (specially under a pandemic
that restricts how much you can go out). Finding a hobby outside of that is
incredibly helpful.

////
2021-09-07 MEETING NOTES:

* start with connectors, don't worry that much b/c the real overhead lies in the
  external dependencies (networking/etc)
* copy stuff from connectors branch into new repo, forget everything else
  https://github.com/tremor-rs/tremor-runtime/blob/main/src/source/blaster.rs
  https://github.com/tremor-rs/tremor-runtime/blob/main/src/sink/blackhole.rs
* try to see if generics are avoidable
* benchmarks:

  cd tremor-cli
  tremor test bench tests
  
  (or)

  ./bench/run.sh <name>
* start async with callbacks for example instead of something more complicated
* for async take a look at how libkafka does it:
  https://github.com/fede1024/rust-rdkafka


* in team building, everyone is different and the team is very homogeneous, you
  have to figure out how to mix them up
* as you get older you talk more and code less
* remember that with time you change, and so does your position in the company
  (developing people instead of code)
* don't care about what others say about you (don't worry)
* take good rest, breathe, coding is mentally exhausting
////

=== How Tremor works

After starting to write the PDK example for connectors and failing because I
didn't know what I was doing, I decided to step back and try to understand in
detail how Tremor works. Once I had that covered, I could try to simplify the
PDK as much as possible in order to keep my sanity.

I jumped into the codebase of `tremor/tremor-runtime` and tried to figure out
how it was structured, also with the help of the team later on. First of all
it's important to know that Tremor is based on the actor model. Quoting
Wikipedia:

[quote, 'https://en.wikipedia.org/wiki/Actor_model[Actor model, Wikipedia]']
____
[The actor model treats the] actor as the universal primitive of concurrent
computation. In response to a message it receives, an actor can: make local
decisions, create more actors, send more messages, and determine how to respond
to the next message received. Actors may modify their own private state, but can
only affect each other indirectly through messaging (removing the need for
lock-based synchronization). 
____

Tremor is currently implemented with
https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)[asynchronous
programming], which means that instead of threads we'll be working with _tasks_,
a higher level concept. From the {{< crate async-std >}} documentation:

[quote, 'https://docs.rs/async-std/1.10.0/async_std/task/index.html[`async_std::task`], docs.rs']
____
An executing asynchronous Rust program consists of a collection of native OS
threads, on top of which multiple stackless coroutines are multiplexed. We refer
to these as “tasks”. Tasks can be named, and provide some built-in support for
synchronization.
____

We could summarize this with the sentence "`Tremor is based on actors running in
separate tasks which communicate asynchronously via channels`". The main actor
is called the `World`. It contains the state of the program, such as the
available artifacts (_repositories_) and the running ones (_registries_), and
it's used to initialize and control the program.

I'll try to follow what Tremor does in order to get a connector running with the
help of a few diagrams. The following diagram showcases what happens when a
`World` is created. This introduces the concept of _Managers_, which simply are
actors in the system that wrap up some functionality.

Managers help decouple the communication and the implementation of the
underlying functionality. They are also useful to remove some boilerplate when
initializing the components, such as creating the communication channel or
spawning the component in a separate task.

Note that they don't necessarily wrap just one component. The top-level
`Manager` helps group up other managers such as `connectors::Manager` or
`pipeline::Manager`:

image::/blog/plugin-dynload/registering.png[width = 100%]

// TODO: builtin types might not be necessary

Once all the managers are initialized, Tremor currently registers all the
built-in artifacts in a "`hardcoded`" way with `register_builtin_types`. But
after the PDK is implemented, this will happen dynamically, i.e. Tremor will
automatically look for DLL/SO files in its configured directory and try to
register all the plugins it can find. The user may additionally request a
specific plugin to be loaded while Tremor is running.

Note that the initialization of the connectors is done in two steps: first
they're _registered_, which just means that the connector is now available for
loading (they're added to the _repository_). The connector doesn't actually
start running until a binding is created with it, for example with
`launch_binding`, which will remove it from the repository and add it to the
_registry_, with the currently running artifacts.

`connectors::Manager` contains all the connectors running in Tremor, which we'll
now try to understand:

image::/blog/plugin-dynload/initializing.png[width = 100%]

Since it's a two-step process, the registering part of it already provides the
tools to initialize the connector (mainly the builder). When someone asks for
the connector to start running, the builder helps to construct it generically
with the provided configuration details. Finally, it's moved into a task of its
own, so that it may communicate with other parts of Tremor.

Now that we have a connector running, let's see how it's split up into the
source and sink parts. In a very similar way, a builder is used to initialize
the underlying source, sink, or both, and then a new task is spawned for them.

A manager is also created for each source and sink, which will handle the
communication with other actors. This way, the source and sink interfaces can be
kept as simple as possible.

image::/blog/plugin-dynload/setting-up.png[width = 100%]

[[actual_start]]
== Taking a look at eBPF first

In the previous articles I mostly considered using either WebAssembly or Dynamic
Loading. What I didn't even know about is https://ebpf.io/[eBPF], "`a
revolutionary technology with origins in the Linux kernel that can run sandboxed
programs in an operating system kernel`". However, similarly to WebAssembly, its
usage has been expanded to user-space applications. eBPF defines a set of
bytecode instructions that may be ran by a virtual machine anywhere, similarly
to how Wasm works.

There are multiple active crates for eBPF in Rust. {{< crate libbpf_rs >}}, {{<
crate redbpf >}} and {{< crate aya >}} are specific to the Linux Kernel. {{<
crate solana_rbpf >}} is a virtual machine, so it only works for user-space. It
seems to be a fork of the now abandoned {{< crate rbpf >}}.

So, is this any better than WebAssembly? Well, not really. In fact, it has the
same exact caveat that made us discard Wasm; for more complex types, one has to
serialize them into a shared memory. It also has a few more restrictions like
only being able to export one function per file or managing imports or exports
manually within the runtime. You can get started quickly with
https://blog.redsift.com/labs/writing-bpf-code-in-rust/[this tutorial from Red
Sift], but I feel like there's less documentation than in the case of Wasm.

Cheers to Dr. TODO for letting me know about this technology -- though he's
considering switching to WebAssembly. He's currently using it to research
pluggable anonymous protocols like Tor, which would allow patches to its code to
happen at runtime. This makes it faster to fix vulnerabilities until it's
properly updated upstream, among other things. TODO add links. Pretty cool :)

== Extending our example

=== Setting up cbindgen

For these first steps I think {{< crate cbindgen >}} will help us understand
what's going on. We can take a look at the generated headers and see how it
works internally. Unfortunately, it fails to run for the `abi_stable` crate:

[source, text]
----
(...)
WARN: Skip abi_stable::CONST - (...)
 
thread 'main' panicked at 'RResult has 2 params but is being instantiated with 1 values', src/bindgen/ir/enumeration.rs:596:9
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
----

This _probably_ has to do with the following warning found in
https://github.com/eqrion/cbindgen/blob/master/docs.md[`cbindgen`'s
documentation]:

____
pass:[NOTE:] A major limitation of cbindgen is that it does not understand
Rust's module system or namespacing. This means that if cbindgen sees that it
needs the definition for `MyType` and there exists two things in your project
with the type name `MyType`, it won't know what to do. Currently, cbindgen's
behaviour is unspecified if this happens. However this may be ok if they have
https://github.com/eqrion/cbindgen/blob/master/docs.md#defines-and-cfgs[different
cfgs].
____

After letting the maintainers of `abi_stable` know about this in
https://github.com/rodrimati1992/abi_stable_crates/issues/52[an issue], they
pointed out that this was expected and that they don't plan on supporting
`cbindgen` because it would take too much effort. Understandable, so let's move
on.

=== Modifying the `Connector` trait for dynamic loading

Now that we know more or less how to approach the PDK, let's try getting a more
complex example running. The plan is to try to simulate the final implementation
of the PDK so that we can run some benchmarks and analyze the overhead it will
introduce. For this, I'll add the `native-connector` and `dynamic-connector`
examples to https://github.com/marioortizmanero/pdk-experiments[the
pdk-experiments repository]. `native-connector` is simply how it currently
works, in a single static executable, and `dynamic-connector` loads the
connectors dynamically as plugins.

Since it may be simpler to get `native-connector` running, let's start with
that. We'll just copy all the necessary code for the
https://github.com/tremor-rs/tremor-runtime/tree/883f13e29b4c6ec7b6703f2487aac321c738e7c8[current
implementation] of connectors as a standalone program:

==== The `Connector` trait

==== The `Value` struct

== Plugin Architecture

In order to load the plugin, one must ensure that the versions of the `common`
crate match for both the runtime and the plugin. Basic metadata such as
versioning must be defined with fully stable types. For example, we can't use
`abi_stable::RStr` to save the version; there might be a version mismatch of
`abi_stable` between the crate and the plugin, and since this happens *before*
making sure they're compatible, it may not work.

All of this is simplified if the macro `define_plugin` is used:

// TODO: explain macro

For now, the version checks are done for the entire crate for simplicity,
but in the future we can make this more flexible. For instance, if a version
bump in this crate only modifies structures for codec plugins, the rest of
the plugins would still work. This would require versioning each of the
types of plugins and bumping them as they're modified. Note that this is
prone to human errors however, as it's a manual process.

// TODO: research https://github.com/doctorn/obake

There may be helpful crates like {{< crate obake >}}.

We'll keep it simple for now, but by exporting the kind of plugin separately
(instead of having an enum `PluginData::Connector`) we can future-proof this.
This is because if we were to deduce the kind of plugin by matching `PluginData`
but one of the single versions that don't affect us mismatched, it may break, as
the layout of the entire enum would change.

== Error Handling

== Setting Up Miri

== Generics

The traits I was trying to make plugin-compatible in Tremor had some instances
of generics. And they'd only get worse in the future with
https://github.com/rust-lang/rust/issues/44265[GATs] and `async` methods in
traits actually being generic as well (we currently use {{< crate async_trait
>}}).

So, first of all let's cross this one out of the checklist. Can we use generics
in the plugins?

=== Why they are impossible

Well, no, generics in plugins are fundamentally impossible. In Rust,
monomorphization turns generic code into specific code by filling in the
concrete types that are used when *compiled* <<generics>>. Plugins are loaded at
runtime, so they may want to use types the compiler didn't generate code for.

It's really easy to prove in Rust with the following example. We'll try to
_load_ an external function with generics:

[source, rust]
----
extern "C" {
    fn foo<T>(_: T);
}
----

This results in the following error:

[source, text]
----
error[E0044]: foreign items may not have type parameters
 --> src/lib.rs:2:5
  |
2 |     fn foo<T>(_: T);
  |     ^^^^^^^^^^^^^^^^ can't have type parameters
  |
  = help: replace the type parameters with concrete types like `u32`

error: aborting due to previous error

For more information about this error, try `rustc --explain E0044`.
----

Interestingly enough, the compiler lets you export generic functions declared
_in Rust_:

[source, rust]
----
extern fn foo<T>(_: T) {}
----

This confused me in the beginning; it made me think generic functions through
FFI would be possible. But as described in
https://github.com/rust-lang/rust/pull/15831[the original issue that allowed
them], they're only supported to pass callbacks to C functions.

Another interesting thing about generics in plugins is that it does work for
lifetimes. This will compile:

[source, rust]
----
extern "C" {
    fn foo<'a>(_: &'a str) -> &'a str;
}
----

That is mainly because even though lifetimes and generics share the same syntax,
in the case of lifetimes they are only annotations. No new versions of the
function are generated.

=== Alternatives

https://adventures.michaelfbryan.com/posts/ffi-safe-polymorphism-in-rust/[Michael
F. Bryan's blog post about `Box<dyn Trait>`] covers pretty well the different
alternatives we have available. Since we can't use generics, `Box<dyn Trait>` is
what we should be using, which makes polymorphism available at runtime. However,
the ABI for `Box<dyn Trait>` is unstable, as it's written in Rust, so we'll have
to find an equivalent alternative.

////
https://adventures.michaelfbryan.com/posts/ffi-safe-polymorphism-in-rust/
https://www.youtube.com/watch?v=xcygqF5LVmM&feature=emb_title

https://docs.rs/typetag/0.1.7/typetag/
https://docs.rs/serde_traitobject/0.2.7/serde_traitobject/
https://docs.rs/thin_trait_object/1.1.2/thin_trait_object/
////

== Conclusion

////
== Benchmarking

I've always wanted to run some benchmarks in order to find out the actual
difference in performance between dynamic loading (with native code) and Wasm
(with interpreted code). Of course, the former will be faster. But, is it
noticeable?

TODO compare with already existing benchmarks, what to expect, etc

Now that I have some examples of both dynamic loading and Wasm plugins, I can
make a few benchmarks in order to see the difference by myself. The `wasm-bench`
and `dynamic-bench` directories in
https://github.com/marioortizmanero/pdk-experiments[pdk-experiments] can be
compiled and then ran with
https://doc.rust-lang.org/1.7.0/book/benchmark-tests.html[Rust's integrated
benchmarking system] (which requires nightly for now)
////

[bibliography]
== References

- [[[generics,       11]]] https://doc.rust-lang.org/book/ch10-01-syntax.html#performance-of-code-using-generics
